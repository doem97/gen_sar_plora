{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Table of contents**<a id='toc0_'></a>    \n",
    "- [Load Local LoRA](#toc1_1_1_)    \n",
    "    - [Load LoRA in A1111 way](#toc1_1_2_)    \n",
    "    - [SFW Example](#toc1_1_3_)    \n",
    "\n",
    "<!-- vscode-jupyter-toc-config\n",
    "\tnumbering=false\n",
    "\tanchor=true\n",
    "\tflat=false\n",
    "\tminLevel=1\n",
    "\tmaxLevel=6\n",
    "\t/vscode-jupyter-toc-config -->\n",
    "<!-- THIS CELL WILL BE REPLACED ON TOC UPDATE. DO NOT WRITE YOUR TEXT IN THIS CELL -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_1_1_'></a>[Load Local LoRA](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from pathlib import Path\n",
    "from diffusers import StableDiffusionPipeline, DPMSolverMultistepScheduler\n",
    "\n",
    "\n",
    "pipe = StableDiffusionPipeline.from_pretrained(\n",
    "    \"runwayml/stable-diffusion-v1-5\",\n",
    "    torch_dtype=torch.float16,\n",
    "    safety_checker=None,\n",
    "    requires_safety_checker=False,\n",
    ")\n",
    "pipe.scheduler = DPMSolverMultistepScheduler.from_config(pipe.scheduler.config)\n",
    "# pipe.unet.load_attn_procs(lora_model_path)\n",
    "pipe.load_lora_weights(\n",
    "    # \"/workspace/dso/GenSAR/LoRA/output/DOSRS_v1/512_sd15_lr1e-04/checkpoint-2700\",\n",
    "    \"/workspace/dso/GenSAR/LoRA/output/DOSRS_v1/shiprs_512_sd15_lr1e-04/checkpoint-2160\",\n",
    "    weight_name=\"pytorch_model.bin\",\n",
    ")\n",
    "pipe.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "user_prompt = \"optical remote sensing,aerial view,cargo ship\"\n",
    "# user_nagative_prompt = \"aircraft,satellite,incomplete ship\"\n",
    "\n",
    "\n",
    "scales = [0.0, 0.2, 0.4, 0.5, 0.6, 0.7, 0.8, 1.0]\n",
    "num_images_per_scale = 3  # Number of images per scale\n",
    "fig, axs = plt.subplots(num_images_per_scale, len(scales), figsize=(16, 7))\n",
    "\n",
    "for i, scale in enumerate(scales):\n",
    "    images = pipe(\n",
    "        prompt=user_prompt,\n",
    "        # negative_prompt=user_nagative_prompt,\n",
    "        width=512,\n",
    "        height=512,\n",
    "        num_inference_steps=25,\n",
    "        guidance_scale=7.5,\n",
    "        num_images_per_prompt=num_images_per_scale,\n",
    "        cross_attention_kwargs={\"scale\": scale},\n",
    "        generator=torch.manual_seed(42),\n",
    "    ).images\n",
    "\n",
    "    for j in range(num_images_per_scale):\n",
    "        axs[j, i].imshow(images[j])\n",
    "        axs[j, i].axis(\"off\")  # To not show axis in each image\n",
    "\n",
    "    axs[0, i].set_title(\n",
    "        f\"scale: {scale}\"\n",
    "    )  # Setting the title to the scale for the first image in each column\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# user_prompt = \"aerial view, entire small cargo ship, (centered:2), full structure visible, deck, cargo containers, sharp, detailed, high resolution, realistic details\"\n",
    "# user_prompt = \"(aerial view of cargo ship:5), tiny cargo ship, elongated target, distinct outline, rectangular shape, centered, multiple cargo decks, deckhouse, bridge structure, onboard cranes, container stacks, Ro-Ro ramps, wide hull\"\n",
    "user_prompt = \"remote sensing,aerial,tiny cargo ship in sea,centered bird view,SAR\"\n",
    "user_nagative_prompt = \"aircraft,satellite,incomplete ship\"\n",
    "\n",
    "images = pipe(\n",
    "    prompt=user_prompt,\n",
    "    negative_prompt=user_nagative_prompt,\n",
    "    width=512,\n",
    "    height=512,\n",
    "    num_inference_steps=25,\n",
    "    guidance_scale=12,\n",
    "    num_images_per_prompt=4,\n",
    "    cross_attention_kwargs={\"scale\": 0.0},\n",
    "    generator=torch.manual_seed(42),\n",
    ").images\n",
    "\n",
    "n = len(images)  # Total number of images\n",
    "plt.figure(figsize=(16, 12))  # Size of the complete figure, adjust as necessary\n",
    "\n",
    "for i in range(n):\n",
    "    plt.subplot(1, n, i + 1)  # Create subplots: 1 row, n columns, index i+1\n",
    "    plt.imshow(images[i])\n",
    "    plt.axis(\"off\")  # To not show axis in each image\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_1_2_'></a>[Load LoRA in A1111 way](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from diffusers import StableDiffusionPipeline, DPMSolverMultistepScheduler\n",
    "\n",
    "# Load the base checkpoint\n",
    "pipeline = StableDiffusionPipeline.from_pretrained(\n",
    "    \"sinkinai/majicMIX-realistic-v5\",\n",
    "    torch_dtype=torch.float16,\n",
    "    safety_checker=None,\n",
    "    requires_safety_checker=False,\n",
    ").to(\"cuda\")\n",
    "pipeline.scheduler = DPMSolverMultistepScheduler.from_config(\n",
    "    pipeline.scheduler.config, use_karras_sigmas=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.load_lora_weights(\n",
    "    \"./data/sd/lora\",\n",
    "    weight_name=\"BeautyNwsjMajic2-01.safetensors\",\n",
    ")\n",
    "prompt = \"masterpiece, best quality, (realskin:1.5), photograph, Figurative buxom [Nymph:God:5], Metallic hair styled as Braided half-up half-down, at Midday, equirectangular 360, Crystal Cubism, Canon 5d mark 4, Low shutter, photorealistic, realistic,8k,highres,cinemagraph\"\n",
    "negative_prompt = \"paintings, sketches, (worst quality:2), (low quality:2), (normal quality:2), lowres, ((monochrome)), ((grayscale)), skin spots, acnes, skin blemishes, age spot, glans, extra fingers, fewer fingers, ((watermark:2)), (white letters:1), (multi nipples), bad anatomy, bad hands, text, error, missing fingers, missing arms, missing legs, extra digit, fewer digits, cropped, worst quality, jpeg artifacts, signature, watermark, username, bad feet, Multiple people, blurry, poorly drawn hands, poorly drawn face, mutation, deformed, extra limbs, extra arms, extra legs, malformed limbs, fused fingers, too many fingers, long neck, cross-eyed, mutated hands, polar lowres, bad body, bad proportions, gross proportions, wrong feet bottom render, abdominal stretch, briefs, knickers, kecks, thong, fused fingers, bad body,bad proportion body to legs, wrong toes, extra toes, missing toes, weird toes, 2 body, 2 pussy, 2 upper, 2 lower, 2 head, 3 hand, 3 feet, extra long leg, super long leg, mirrored image, mirrored noise, badhandv4, ng_deepnegative_v1_75t\"\n",
    "\n",
    "images = pipeline(\n",
    "    prompt=prompt,\n",
    "    negative_prompt=negative_prompt,\n",
    "    width=512,\n",
    "    height=768,\n",
    "    num_inference_steps=25,\n",
    "    guidance_scale=12,\n",
    "    num_images_per_prompt=4,\n",
    "    cross_attention_kwargs={\"scale\": 1.0},\n",
    "    generator=torch.manual_seed(2555690106),\n",
    ").images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.load_lora_weights(\n",
    "    \"./data/sd/lora\",\n",
    "    weight_name=\"methurlant.safetensors\",\n",
    ")\n",
    "prompt = \"1 beautiful female long hair, druid, forest, methurlant Alan Lee abstract , gradient color realistic, photorealistic fantasy\"\n",
    "negative_prompt = \"((worst quality))\"\n",
    "\n",
    "images = pipeline(\n",
    "    prompt=prompt,\n",
    "    negative_prompt=negative_prompt,\n",
    "    width=512,\n",
    "    height=768,\n",
    "    num_inference_steps=25,\n",
    "    guidance_scale=7,\n",
    "    num_images_per_prompt=4,\n",
    "    cross_attention_kwargs={\"scale\": 1.0},\n",
    "    generator=torch.manual_seed(2555690106),\n",
    ").images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original w/o LoRA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "n = len(images)  # Total number of images\n",
    "plt.figure(figsize=(16, 12))  # Size of the complete figure, adjust as necessary\n",
    "\n",
    "for i in range(n):\n",
    "    plt.subplot(1, n, i + 1)  # Create subplots: 1 row, n columns, index i+1\n",
    "    plt.imshow(images[i])\n",
    "    plt.axis(\"off\")  # To not show axis in each image\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# W/ LoRA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "n = len(images)  # Total number of images\n",
    "plt.figure(figsize=(16, 12))  # Size of the complete figure, adjust as necessary\n",
    "\n",
    "for i in range(n):\n",
    "    plt.subplot(1, n, i + 1)  # Create subplots: 1 row, n columns, index i+1\n",
    "    plt.imshow(images[i])\n",
    "    plt.axis(\"off\")  # To not show axis in each image\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_1_3_'></a>[SFW Example](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from diffusers import StableDiffusionPipeline, DPMSolverMultistepScheduler\n",
    "\n",
    "# Load the base checkpoint\n",
    "pipeline = StableDiffusionPipeline.from_pretrained(\n",
    "    \"philz1337/revanimated\",\n",
    "    torch_dtype=torch.float16,\n",
    "    safety_checker=None,\n",
    "    requires_safety_checker=False,\n",
    ").to(\"cuda\")\n",
    "pipeline.scheduler = DPMSolverMultistepScheduler.from_config(\n",
    "    pipeline.scheduler.config, use_karras_sigmas=True\n",
    ")\n",
    "\n",
    "pipeline.load_lora_weights(\n",
    "    \"samecorner/blindbox\", weight_name=\"blindbox_v1_mix.safetensors\"\n",
    ")\n",
    "user_prompt = \"chinese dragon, furry, fluffy, gradient color ((best quality)), ((masterpiece)), ( extreme detailed, highest detailed, official art, beautiful and aesthetic:1.2),  depth of field, composition, FULL BODY, (CHIBI), (beautiful and detailed eye:1.3),(very happy:1)\"\n",
    "user_negative_prompt = \"((badhandv4, easynegative, ng_deepnegative_v1_75t, verybadimagenegative_v1.3)),(bad anatomy), monochrome, grayscale, (text, words, logo, watermark)\"\n",
    "\n",
    "images = pipeline(\n",
    "    prompt=user_prompt,\n",
    "    negative_prompt=user_negative_prompt,\n",
    "    width=512,\n",
    "    height=768,\n",
    "    num_inference_steps=25,\n",
    "    guidance_scale=7,\n",
    "    num_images_per_prompt=4,\n",
    "    cross_attention_kwargs={\"scale\": 0.0},\n",
    "    generator=torch.manual_seed(42),\n",
    ").images\n",
    "\n",
    "# W/ LoRA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "n = len(images)  # Total number of images\n",
    "plt.figure(figsize=(16, 12))  # Size of the complete figure, adjust as necessary\n",
    "\n",
    "for i in range(n):\n",
    "    plt.subplot(1, n, i + 1)  # Create subplots: 1 row, n columns, index i+1\n",
    "    plt.imshow(images[i])\n",
    "    plt.axis(\"off\")  # To not show axis in each image\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from diffusers import StableDiffusionPipeline, DPMSolverMultistepScheduler\n",
    "\n",
    "# Load the base checkpoint\n",
    "pipeline = StableDiffusionPipeline.from_pretrained(\n",
    "    \"philz1337/revanimated\",\n",
    "    torch_dtype=torch.float16,\n",
    "    safety_checker=None,\n",
    "    requires_safety_checker=False,\n",
    ").to(\"cuda\")\n",
    "pipeline.scheduler = DPMSolverMultistepScheduler.from_config(\n",
    "    pipeline.scheduler.config, use_karras_sigmas=True\n",
    ")\n",
    "\n",
    "pipeline.load_lora_weights(\n",
    "    \"samecorner/blindbox\", weight_name=\"blindbox_v1_mix.safetensors\"\n",
    ")\n",
    "user_prompt = \"(masterpiece),(best quality),(ultra-detailed), (full body:1.2), 1girl,chibi,cute, smile, white Bob haircut, red eyes, earring, white shirt,black skirt, lace legwear, (sitting on red sofa), seductive posture, smile, A sleek black coffee table sits in front of the sofa and a few decorative items are placed on the shelves, (beautiful detailed face), (beautiful detailed eyes)\"\n",
    "user_negative_prompt = \"(low quality:1.3), (worst quality:1.3)\"\n",
    "\n",
    "\n",
    "images = pipeline(\n",
    "    prompt=user_prompt,\n",
    "    negative_prompt=user_negative_prompt,\n",
    "    width=512,\n",
    "    height=768,\n",
    "    num_inference_steps=25,\n",
    "    guidance_scale=7,\n",
    "    num_images_per_prompt=4,\n",
    "    cross_attention_kwargs={\"scale\": 3.0},\n",
    "    generator=torch.manual_seed(42),\n",
    ").images\n",
    "\n",
    "# W/ LoRA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "n = len(images)  # Total number of images\n",
    "plt.figure(figsize=(16, 12))  # Size of the complete figure, adjust as necessary\n",
    "\n",
    "for i in range(n):\n",
    "    plt.subplot(1, n, i + 1)  # Create subplots: 1 row, n columns, index i+1\n",
    "    plt.imshow(images[i])\n",
    "    plt.axis(\"off\")  # To not show axis in each image\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# pipeline.load_lora_weights(\n",
    "#     \"./data/sd/lora\",\n",
    "#     weight_name=\"3DMM_V7.safetensors\",\n",
    "# )\n",
    "\n",
    "pipeline.load_lora_weights(\n",
    "    \"samecorner/blindbox\", weight_name=\"blindbox_v1_mix.safetensors\"\n",
    ")\n",
    "user_prompt = \"(masterpiece),(best quality),(ultra-detailed), (full body:1.2), 1girl,chibi,cute, smile, white Bob haircut, red eyes, earring, white shirt,black skirt, lace legwear, (sitting on red sofa), seductive posture, smile, A sleek black coffee table sits in front of the sofa and a few decorative items are placed on the shelves, (beautiful detailed face), (beautiful detailed eyes)\"\n",
    "user_negative_prompt = \"(low quality:1.3), (worst quality:1.3)\"\n",
    "\n",
    "scales = [0.0, 0.5, 1.0, 1.5, 2.0]\n",
    "num_images_per_scale = 3  # Number of images per scale\n",
    "\n",
    "fig, axs = plt.subplots(num_images_per_scale, len(scales), figsize=(16, 9))\n",
    "\n",
    "for i, scale in enumerate(scales):\n",
    "    images = pipeline(\n",
    "        prompt=user_prompt,\n",
    "        negative_prompt=user_negative_prompt,\n",
    "        width=512,\n",
    "        height=768,\n",
    "        num_inference_steps=25,\n",
    "        guidance_scale=7,\n",
    "        num_images_per_prompt=num_images_per_scale,\n",
    "        cross_attention_kwargs={\"scale\": scale},\n",
    "        generator=torch.manual_seed(42),\n",
    "    ).images\n",
    "\n",
    "    for j in range(num_images_per_scale):\n",
    "        axs[j, i].imshow(images[j])\n",
    "        axs[j, i].axis(\"off\")  # To not show axis in each image\n",
    "\n",
    "    axs[0, i].set_title(\n",
    "        f\"scale: {scale}\"\n",
    "    )  # Setting the title to the scale for the first image in each column\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# pipeline.load_lora_weights(\n",
    "#     \"./data/sd/lora\",\n",
    "#     weight_name=\"3DMM_V7.safetensors\",\n",
    "# )\n",
    "\n",
    "pipeline.load_lora_weights(\n",
    "    \"samecorner/blindbox\", weight_name=\"blindbox_v1_mix.safetensors\"\n",
    ")\n",
    "user_prompt = \"chinese dragon, furry, fluffy, gradient color ((best quality)), ((masterpiece)), ( extreme detailed, highest detailed, official art, beautiful and aesthetic:1.2),  depth of field, composition, FULL BODY, (CHIBI), (beautiful and detailed eye:1.3),(very happy:1)\"\n",
    "user_negative_prompt = \"((badhandv4, easynegative, ng_deepnegative_v1_75t, verybadimagenegative_v1.3)),(bad anatomy), monochrome, grayscale, (text, words, logo, watermark)\"\n",
    "\n",
    "scales = [0.0, 0.5, 1.0, 1.5, 2.0]\n",
    "num_images_per_scale = 3  # Number of images per scale\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(num_images_per_scale, len(scales), figsize=(16, 9))\n",
    "\n",
    "for i, scale in enumerate(scales):\n",
    "    images = pipeline(\n",
    "        prompt=user_prompt,\n",
    "        negative_prompt=user_negative_prompt,\n",
    "        width=512,\n",
    "        height=512,\n",
    "        num_inference_steps=25,\n",
    "        guidance_scale=7.5,\n",
    "        num_images_per_prompt=num_images_per_scale,\n",
    "        cross_attention_kwargs={\"scale\": scale},\n",
    "        generator=torch.manual_seed(42),\n",
    "    ).images\n",
    "\n",
    "    for j in range(num_images_per_scale):\n",
    "        axs[j, i].imshow(images[j])\n",
    "        axs[j, i].axis(\"off\")  # To not show axis in each image\n",
    "\n",
    "    axs[0, i].set_title(\n",
    "        f\"scale: {scale}\"\n",
    "    )  # Setting the title to the scale for the first image in each column\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import torch\n",
    "\n",
    "from diffusers import StableDiffusionPipeline, DPMSolverMultistepScheduler\n",
    "\n",
    "# Load the base checkpoint\n",
    "pipeline = StableDiffusionPipeline.from_pretrained(\n",
    "    \"digiplay/GhostMixV1.2VAE\",\n",
    "    torch_dtype=torch.float16,\n",
    "    safety_checker=None,\n",
    "    requires_safety_checker=False,\n",
    ").to(\"cuda\")\n",
    "pipeline.scheduler = DPMSolverMultistepScheduler.from_config(\n",
    "    pipeline.scheduler.config, use_karras_sigmas=True\n",
    ")\n",
    "\n",
    "# pipeline.load_lora_weights(\n",
    "#     \"./data/sd/lora\",\n",
    "#     weight_name=\"3DMM_V7.safetensors\",\n",
    "# )\n",
    "\n",
    "pipeline.load_lora_weights(\n",
    "    \"./data/sd/lora\", weight_name=\"kVoidEnergy-000001.safetensors\"\n",
    ")\n",
    "user_prompt = \"(masterpiece, best quality:1.4),(absurdres, highres, ultra detailed:1.2), (1 handsome man:1.4),(using dark magic:1.4),purple magic,playful illustrations, fractal art,imaginative overlays, artistic fusion,fantastical scenes, evocative narratives, striking visuals, upper body\"\n",
    "user_negative_prompt = \"(worst quality, low quality:2), NSFW,monochrome, zombie,overexposure, watermark,text,bad anatomy,bad hand,((extra hands)),extra fingers,too many fingers,fused fingers,bad arm,distorted arm,extra arms,fused arms,extra legs,missing leg,disembodied leg,extra nipples, detached arm, liquid hand,inverted hand,disembodied limb, oversized head,extra body,extra navel,easynegative,(hair between eyes),sketch, duplicate, ugly, huge eyes, text, logo, worst face, (bad and mutated hands:1.3), (blurry:2.0), horror, geometry, bad_prompt, (bad hands), (missing fingers), multiple limbs, bad anatomy, (interlocked fingers:1.2), Ugly Fingers, (extra digit and hands and fingers and legs and arms:1.4), (deformed fingers:1.2), (long fingers:1.2),(bad-artist-anime), bad-artist, bad hand, extra legs ,(ng_deepnegative_v1_75t),((hands on head))\"\n",
    "\n",
    "scales = [0.0, 0.5, 1.0, 1.5, 2.0]\n",
    "num_images_per_scale = 3  # Number of images per scale\n",
    "\n",
    "fig, axs = plt.subplots(num_images_per_scale, len(scales), figsize=(16, 9))\n",
    "\n",
    "for i, scale in enumerate(scales):\n",
    "    images = pipeline(\n",
    "        prompt=user_prompt,\n",
    "        negative_prompt=user_negative_prompt,\n",
    "        width=512,\n",
    "        height=512,\n",
    "        num_inference_steps=25,\n",
    "        guidance_scale=7.5,\n",
    "        num_images_per_prompt=num_images_per_scale,\n",
    "        cross_attention_kwargs={\"scale\": scale},\n",
    "        generator=torch.manual_seed(43),\n",
    "    ).images\n",
    "\n",
    "    for j in range(num_images_per_scale):\n",
    "        axs[j, i].imshow(images[j])\n",
    "        axs[j, i].axis(\"off\")  # To not show axis in each image\n",
    "\n",
    "    axs[0, i].set_title(\n",
    "        f\"scale: {scale}\"\n",
    "    )  # Setting the title to the scale for the first image in each column\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "from diffusers import StableDiffusionPipeline, DPMSolverMultistepScheduler\n",
    "\n",
    "# Load the base checkpoint\n",
    "# pipeline = StableDiffusionPipeline.from_pretrained(\n",
    "#     \"emilianJR/chilloutmix_NiPrunedFp32Fix\",\n",
    "#     torch_dtype=torch.float32,\n",
    "#     safety_checker=None,\n",
    "#     requires_safety_checker=False,\n",
    "# ).to(\"cuda\")\n",
    "# pipeline = StableDiffusionPipeline.from_pretrained(\n",
    "#     \"philz1337/revanimated\",\n",
    "#     torch_dtype=torch.float16,\n",
    "#     safety_checker=None,\n",
    "#     requires_safety_checker=False,\n",
    "# ).to(\"cuda\")\n",
    "pipeline = StableDiffusionPipeline.from_ckpt(\n",
    "    \"https://huggingface.co/hanafuusen2001/ReVAnimated/blob/main/revAnimated_v122.safetensors\",\n",
    "    torch_dtype=torch.float16,\n",
    "    safety_checker=None,\n",
    "    requires_safety_checker=False,\n",
    ").to(\"cuda\")\n",
    "pipeline.scheduler = DPMSolverMultistepScheduler.from_config(\n",
    "    pipeline.scheduler.config, use_karras_sigmas=True\n",
    ")\n",
    "\n",
    "pipeline.load_lora_weights(\"./data/sd/lora\", weight_name=\"3DMM_V7.safetensors\")\n",
    "# user_prompt = \"masterpiece, chinese dragon, long dragon, Loong,fangs,fantasy, mythical, art by( greg rutkowski:0.8), epic lighting, (photo realism:1.2), high quality, highly detailed, masterpiece, epic\"\n",
    "# user_negative_prompt = \"(worst quality:2), (low quality:2), (normal quality:2), lowres, normal quality, ((monochrome)), ((grayscale)), skin spots, acnes, skin blemishes, age spot, glans,extra fingers,fewer fingers,strange fingers,bad hand (low quality, worst quality:1.4), (bad_prompt:0.8), (monochrome), (greyscale)\"\n",
    "user_prompt = \"(upper body), best quality, (masterpiece:1.3),jesus, priest at church, hands together, (looking up:1.1), black hair, blue eyes, (chibi:0.7), streaks of light, cinematic lighting, side lighting, halo, epic composition\"\n",
    "user_negative_prompt = \"badhandv4, paintings, sketches, (worst qualit:2), (low quality:2), (normal quality:2), lowers, normal quality, ((monochrome)), ((grayscale)), skin spots, acnes, skin blemishes, age spot, (outdoor:1.6), manboobs, (backlight:1.2), double navel, muted arms, hused arms, neck lace, analog, analog effects, (sunglass:1.4), nipples, nsfw, bad architecture, watermark, (mole:1.5), EasyNegative\"\n",
    "\n",
    "\n",
    "# images = pipeline(\n",
    "#     prompt=user_prompt,\n",
    "#     negative_prompt=user_negative_prompt,\n",
    "#     width=512,\n",
    "#     height=768,\n",
    "#     num_inference_steps=30,\n",
    "#     guidance_scale=7,\n",
    "#     num_images_per_prompt=4,\n",
    "#     cross_attention_kwargs={\"scale\": 2.0},\n",
    "#     generator=torch.manual_seed(42),\n",
    "# ).images\n",
    "\n",
    "# # W/ LoRA\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# n = len(images)  # Total number of images\n",
    "# plt.figure(figsize=(16, 12))  # Size of the complete figure, adjust as necessary\n",
    "\n",
    "# for i in range(n):\n",
    "#     plt.subplot(1, n, i + 1)  # Create subplots: 1 row, n columns, index i+1\n",
    "#     plt.imshow(images[i])\n",
    "#     plt.axis(\"off\")  # To not show axis in each image\n",
    "\n",
    "# plt.show()\n",
    "\n",
    "scales = [0.0, 0.375, 0.75, 1.125, 1.5]\n",
    "# scales = [0.0, 1.0]\n",
    "num_images_per_scale = 3  # Number of images per scale\n",
    "\n",
    "fig, axs = plt.subplots(num_images_per_scale, len(scales), figsize=(16, 9))\n",
    "\n",
    "for i, scale in enumerate(scales):\n",
    "    images = pipeline(\n",
    "        prompt=user_prompt,\n",
    "        negative_prompt=user_negative_prompt,\n",
    "        width=512,\n",
    "        height=512,\n",
    "        num_inference_steps=30,\n",
    "        guidance_scale=7,\n",
    "        num_images_per_prompt=num_images_per_scale,\n",
    "        cross_attention_kwargs={\"scale\": scale},\n",
    "        generator=torch.manual_seed(42),\n",
    "    ).images\n",
    "\n",
    "    for j in range(num_images_per_scale):\n",
    "        axs[j, i].imshow(images[j])\n",
    "        axs[j, i].axis(\"off\")  # To not show axis in each image\n",
    "\n",
    "    axs[0, i].set_title(\n",
    "        f\"scale: {scale}\"\n",
    "    )  # Setting the title to the scale for the first image in each column\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from diffusers import StableDiffusionPipeline, DPMSolverMultistepScheduler\n",
    "\n",
    "# Load the base checkpoint\n",
    "pipeline = StableDiffusionPipeline.from_pretrained(\n",
    "    \"philz1337/revanimated\",\n",
    "    torch_dtype=torch.float16,\n",
    "    safety_checker=None,\n",
    "    requires_safety_checker=False,\n",
    ").to(\"cuda\")\n",
    "pipeline.scheduler = DPMSolverMultistepScheduler.from_config(\n",
    "    pipeline.scheduler.config, use_karras_sigmas=True\n",
    ")\n",
    "\n",
    "pipeline.load_lora_weights(\n",
    "    \"samecorner/blindbox\", weight_name=\"blindbox_v1_mix.safetensors\"\n",
    ")\n",
    "user_prompt = \"(masterpiece),(best quality),(ultra-detailed), (full body:1.2), 1girl,chibi,cute, smile, white Bob haircut, red eyes, earring, white shirt,black skirt, lace legwear, (sitting on red sofa), seductive posture, smile, A sleek black coffee table sits in front of the sofa and a few decorative items are placed on the shelves, (beautiful detailed face), (beautiful detailed eyes)\"\n",
    "user_negative_prompt = \"(low quality:1.3), (worst quality:1.3)\"\n",
    "\n",
    "\n",
    "images = pipeline(\n",
    "    prompt=user_prompt,\n",
    "    negative_prompt=user_negative_prompt,\n",
    "    width=512,\n",
    "    height=768,\n",
    "    num_inference_steps=25,\n",
    "    guidance_scale=7,\n",
    "    num_images_per_prompt=4,\n",
    "    cross_attention_kwargs={\"scale\": 3.0},\n",
    "    generator=torch.manual_seed(42),\n",
    ").images\n",
    "\n",
    "# W/ LoRA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "n = len(images)  # Total number of images\n",
    "plt.figure(figsize=(16, 12))  # Size of the complete figure, adjust as necessary\n",
    "\n",
    "for i in range(n):\n",
    "    plt.subplot(1, n, i + 1)  # Create subplots: 1 row, n columns, index i+1\n",
    "    plt.imshow(images[i])\n",
    "    plt.axis(\"off\")  # To not show axis in each image\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hgface",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
