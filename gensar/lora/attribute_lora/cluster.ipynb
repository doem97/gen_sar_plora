{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loads checkpoint by local backend from path: /workspace/dso/clsar/outputs/res50_fusrs_v2_pretrain/res50_1x128_lr1e-1+200e+im21k_fusrs_v2/best_f1_score_epoch_158.pth\n",
      "The model and loaded state dict do not match exactly\n",
      "\n",
      "unexpected key in source state_dict: head.fc.weight, head.fc.bias\n",
      "\n",
      "features shape: (6848, 2048)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/mmpretrain/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustering done and labels saved!\n",
      "Confusion matrix: (Original classes x New clusters)\n",
      "[[1513  153  417 1299]\n",
      " [ 171    2    8   91]\n",
      " [ 354  149   45  368]\n",
      " [ 876  128   76  843]\n",
      " [ 239    4   23   89]]\n",
      "cargo: [1513  153  417 1299]\n",
      "dredger: [171   2   8  91]\n",
      "fishing: [354 149  45 368]\n",
      "other: [876 128  76 843]\n",
      "tanker: [239   4  23  89]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from mmpretrain import get_model\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.transforms import transforms\n",
    "from sklearn.cluster import KMeans\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "torch.cuda.set_device(7)\n",
    "\n",
    "\n",
    "# Load ResNet50 model and remove the final classification layer\n",
    "def load_resnet50_model(model_pth):\n",
    "    pre_trained_ResNet50 = model_pth\n",
    "    # Initialize SAR pre-trained ResNet50\n",
    "    model = get_model(\n",
    "        \"resnet50_8xb32_in1k\",\n",
    "        head=None,  # to extract only activation vectors\n",
    "        pretrained=pre_trained_ResNet50,\n",
    "    ).cuda()\n",
    "    model = model.eval()\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "# Extract features from images using ResNet50\n",
    "def extract_features(dataloader, model):\n",
    "    features_list = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, _ in dataloader:\n",
    "            inputs = inputs.cuda()\n",
    "            features = model(inputs)[0]\n",
    "            # features: batch_size x 2048 (before FC layer but after GAP)\n",
    "            features = features.reshape(features.size(0), -1)\n",
    "            features_list.append(features.cpu().numpy())\n",
    "\n",
    "    return np.vstack(features_list)\n",
    "\n",
    "\n",
    "# Load dataset\n",
    "data_transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(\n",
    "            mean=[11.20954390854399, 11.20954390854399, 11.20954390854399],\n",
    "            std=[20.241805767392393, 20.241805767392393, 20.241805767392393],\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "dataset = ImageFolder(\n",
    "    root=\"/workspace/data/fusrs_v2/vgg_format\", transform=data_transform\n",
    ")\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=False, num_workers=4)\n",
    "\n",
    "# Extract features using ResNet50\n",
    "model = load_resnet50_model(\n",
    "    model_pth=\"/workspace/dso/clsar/outputs/res50_fusrs_v2_pretrain/res50_1x128_lr1e-1+200e+im21k_fusrs_v2/best_f1_score_epoch_158.pth\"\n",
    ")\n",
    "features = extract_features(dataloader, model)\n",
    "print(f\"features shape: {features.shape}\")\n",
    "\n",
    "# Cluster features using K-means\n",
    "kmeans = KMeans(n_clusters=4, random_state=0).fit(features)\n",
    "labels = kmeans.predict(features)\n",
    "\n",
    "# Create a dictionary mapping from original image paths to new labels\n",
    "path_to_label = {path: label for path, label in zip(dataset.samples, labels)}\n",
    "\n",
    "\n",
    "# Optionally, you can save this mapping to a file for future reference\n",
    "with open(\"./cluster_labels_c4.txt\", \"w\") as f:\n",
    "    for path, label in path_to_label.items():\n",
    "        f.write(f\"{path[0]},{path[1]},{label}\\n\")\n",
    "\n",
    "print(\"Clustering done and labels saved!\")\n",
    "\n",
    "\n",
    "# Extract the original labels from the dataset\n",
    "original_labels = [label for _, label in dataset.samples]\n",
    "\n",
    "# Create a matrix to store counts\n",
    "# num_classes: the total number of original classes\n",
    "num_classes = len(dataset.classes)\n",
    "confusion_matrix = np.zeros((num_classes, 4), dtype=int)\n",
    "\n",
    "# Populate the confusion matrix\n",
    "for original_label, cluster_label in zip(original_labels, labels):\n",
    "    confusion_matrix[original_label, cluster_label] += 1\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(\"Confusion matrix: (Original classes x New clusters)\")\n",
    "print(confusion_matrix)\n",
    "\n",
    "# Optionally, you can also print the matrix with class names for clarity\n",
    "for original_class, row in zip(dataset.classes, confusion_matrix):\n",
    "    print(f\"{original_class}: {row}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 11:\n",
      "  Original Class 0: 445\n",
      "  Original Class 1: 75\n",
      "  Original Class 2: 44\n",
      "  Original Class 3: 139\n",
      "  Original Class 4: 44\n",
      "\n",
      "Cluster 3:\n",
      "  Original Class 0: 583\n",
      "  Original Class 1: 82\n",
      "  Original Class 2: 64\n",
      "  Original Class 3: 246\n",
      "  Original Class 4: 171\n",
      "\n",
      "Cluster 1:\n",
      "  Original Class 0: 415\n",
      "  Original Class 1: 17\n",
      "  Original Class 2: 45\n",
      "  Original Class 3: 89\n",
      "  Original Class 4: 24\n",
      "\n",
      "Cluster 4:\n",
      "  Original Class 0: 264\n",
      "  Original Class 1: 20\n",
      "  Original Class 2: 30\n",
      "  Original Class 3: 86\n",
      "  Original Class 4: 23\n",
      "\n",
      "Cluster 5:\n",
      "  Original Class 0: 307\n",
      "  Original Class 1: 29\n",
      "  Original Class 2: 70\n",
      "  Original Class 3: 68\n",
      "  Original Class 4: 27\n",
      "\n",
      "Cluster 0:\n",
      "  Original Class 0: 162\n",
      "  Original Class 1: 7\n",
      "  Original Class 2: 18\n",
      "  Original Class 3: 15\n",
      "  Original Class 4: 26\n",
      "\n",
      "Cluster 14:\n",
      "  Original Class 0: 475\n",
      "  Original Class 1: 14\n",
      "  Original Class 2: 62\n",
      "  Original Class 3: 174\n",
      "  Original Class 4: 22\n",
      "\n",
      "Cluster 7:\n",
      "  Original Class 0: 196\n",
      "  Original Class 1: 1\n",
      "  Original Class 2: 95\n",
      "  Original Class 3: 130\n",
      "  Original Class 4: 3\n",
      "\n",
      "Cluster 10:\n",
      "  Original Class 0: 169\n",
      "  Original Class 1: 10\n",
      "  Original Class 2: 74\n",
      "  Original Class 3: 68\n",
      "  Original Class 4: 2\n",
      "\n",
      "Cluster 13:\n",
      "  Original Class 0: 224\n",
      "  Original Class 1: 13\n",
      "  Original Class 2: 209\n",
      "  Original Class 3: 423\n",
      "  Original Class 4: 9\n",
      "\n",
      "Cluster 2:\n",
      "  Original Class 0: 52\n",
      "  Original Class 1: 3\n",
      "  Original Class 2: 23\n",
      "  Original Class 3: 11\n",
      "\n",
      "Cluster 8:\n",
      "  Original Class 0: 34\n",
      "  Original Class 1: 1\n",
      "  Original Class 2: 122\n",
      "  Original Class 3: 396\n",
      "  Original Class 4: 1\n",
      "\n",
      "Cluster 9:\n",
      "  Original Class 0: 47\n",
      "  Original Class 2: 39\n",
      "  Original Class 3: 44\n",
      "  Original Class 4: 3\n",
      "\n",
      "Cluster 15:\n",
      "  Original Class 0: 1\n",
      "  Original Class 2: 2\n",
      "  Original Class 3: 7\n",
      "\n",
      "Cluster 6:\n",
      "  Original Class 0: 6\n",
      "  Original Class 2: 19\n",
      "  Original Class 3: 14\n",
      "\n",
      "Cluster 12:\n",
      "  Original Class 0: 2\n",
      "  Original Class 3: 13\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "# Read the image_labels.txt file to get the mappings\n",
    "with open(\"cluster_labels.txt\", \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "# Extract path, original label, and new cluster label from each line\n",
    "path_to_labels = {\n",
    "    line.split(\",\")[0]: (int(line.split(\",\")[1]), int(line.split(\",\")[2]))\n",
    "    for line in lines\n",
    "}\n",
    "\n",
    "# Determine the distribution of original classes within each cluster\n",
    "cluster_to_class_distribution = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "# Extract path, original label, and new cluster label from each line\n",
    "path_to_labels = {\n",
    "    line.split(\",\")[0]: (int(line.split(\",\")[1]), int(line.split(\",\")[2]))\n",
    "    for line in lines\n",
    "}\n",
    "\n",
    "for path, (original_label, cluster) in path_to_labels.items():\n",
    "    cluster_to_class_distribution[cluster][original_label] += 1\n",
    "\n",
    "# Print the distribution for each cluster\n",
    "for cluster, class_distribution in cluster_to_class_distribution.items():\n",
    "    print(f\"Cluster {cluster}:\")\n",
    "    for original_class, count in class_distribution.items():\n",
    "        print(f\"  Original Class {original_class}: {count}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution Matrix:\n",
      "[[162. 415.  52. 583. 264. 307.   6. 196.  34.  47. 169. 445.   2. 224.\n",
      "  475.   1.]\n",
      " [  7.  17.   3.  82.  20.  29.   0.   1.   1.   0.  10.  75.   0.  13.\n",
      "   14.   0.]\n",
      " [ 18.  45.  23.  64.  30.  70.  19.  95. 122.  39.  74.  44.   0. 209.\n",
      "   62.   2.]\n",
      " [ 15.  89.  11. 246.  86.  68.  14. 130. 396.  44.  68. 139.  13. 423.\n",
      "  174.   7.]\n",
      " [ 26.  24.   0. 171.  23.  27.   0.   3.   1.   3.   2.  44.   0.   9.\n",
      "   22.   0.]]\n",
      "Original Class 0: Cluster 0: 162.0 | Cluster 1: 415.0 | Cluster 2: 52.0 | Cluster 3: 583.0 | Cluster 4: 264.0 | Cluster 5: 307.0 | Cluster 6: 6.0 | Cluster 7: 196.0 | Cluster 8: 34.0 | Cluster 9: 47.0 | Cluster 10: 169.0 | Cluster 11: 445.0 | Cluster 12: 2.0 | Cluster 13: 224.0 | Cluster 14: 475.0 | Cluster 15: 1.0 | \n",
      "Original Class 1: Cluster 0: 7.0 | Cluster 1: 17.0 | Cluster 2: 3.0 | Cluster 3: 82.0 | Cluster 4: 20.0 | Cluster 5: 29.0 | Cluster 6: 0.0 | Cluster 7: 1.0 | Cluster 8: 1.0 | Cluster 9: 0.0 | Cluster 10: 10.0 | Cluster 11: 75.0 | Cluster 12: 0.0 | Cluster 13: 13.0 | Cluster 14: 14.0 | Cluster 15: 0.0 | \n",
      "Original Class 2: Cluster 0: 18.0 | Cluster 1: 45.0 | Cluster 2: 23.0 | Cluster 3: 64.0 | Cluster 4: 30.0 | Cluster 5: 70.0 | Cluster 6: 19.0 | Cluster 7: 95.0 | Cluster 8: 122.0 | Cluster 9: 39.0 | Cluster 10: 74.0 | Cluster 11: 44.0 | Cluster 12: 0.0 | Cluster 13: 209.0 | Cluster 14: 62.0 | Cluster 15: 2.0 | \n",
      "Original Class 3: Cluster 0: 15.0 | Cluster 1: 89.0 | Cluster 2: 11.0 | Cluster 3: 246.0 | Cluster 4: 86.0 | Cluster 5: 68.0 | Cluster 6: 14.0 | Cluster 7: 130.0 | Cluster 8: 396.0 | Cluster 9: 44.0 | Cluster 10: 68.0 | Cluster 11: 139.0 | Cluster 12: 13.0 | Cluster 13: 423.0 | Cluster 14: 174.0 | Cluster 15: 7.0 | \n",
      "Original Class 4: Cluster 0: 26.0 | Cluster 1: 24.0 | Cluster 2: 0.0 | Cluster 3: 171.0 | Cluster 4: 23.0 | Cluster 5: 27.0 | Cluster 6: 0.0 | Cluster 7: 3.0 | Cluster 8: 1.0 | Cluster 9: 3.0 | Cluster 10: 2.0 | Cluster 11: 44.0 | Cluster 12: 0.0 | Cluster 13: 9.0 | Cluster 14: 22.0 | Cluster 15: 0.0 | \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "# Read the image_labels.txt file to get the mappings\n",
    "with open(\"cluster_labels.txt\", \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "# Extract path, original label, and new cluster label from each line\n",
    "path_to_labels = {\n",
    "    line.split(\",\")[0]: (int(line.split(\",\")[1]), int(line.split(\",\")[2].strip()))\n",
    "    for line in lines\n",
    "}\n",
    "\n",
    "# Create a matrix for the distribution\n",
    "# Note: This assumes original labels are sequential integers starting from 0.\n",
    "# Adjust max_original_label and num_clusters accordingly if different.\n",
    "max_original_label = max([original for original, _ in path_to_labels.values()]) + 1\n",
    "num_clusters = 16\n",
    "distribution_matrix = np.zeros((max_original_label, num_clusters))\n",
    "\n",
    "for _, (original_label, cluster) in path_to_labels.items():\n",
    "    distribution_matrix[original_label][cluster] += 1\n",
    "\n",
    "# Print the distribution matrix\n",
    "print(\"Distribution Matrix:\")\n",
    "print(distribution_matrix)\n",
    "\n",
    "# If you want a more detailed print:\n",
    "for i, row in enumerate(distribution_matrix):\n",
    "    print(f\"Original Class {i}:\", end=\" \")\n",
    "    for j, count in enumerate(row):\n",
    "        print(f\"Cluster {j}: {count}\", end=\" | \")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tC0\tC1\tC2\tC3\n",
      "------------------------------------------------\n",
      "Class 0\t1513\t153\t417\t1299\n",
      "Class 1\t171\t2\t8\t91\n",
      "Class 2\t354\t149\t45\t368\n",
      "Class 3\t876\t128\t76\t843\n",
      "Class 4\t239\t4\t23\t89\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "# Read the image_labels.txt file\n",
    "with open(\"cluster_labels_c4.txt\", \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "# Extract path, original label, and new cluster label from each line\n",
    "path_to_labels = {\n",
    "    line.split(\",\")[0]: (int(line.split(\",\")[1]), int(line.split(\",\")[2]))\n",
    "    for line in lines\n",
    "}\n",
    "\n",
    "# Determine the distribution of original classes within each cluster\n",
    "class_to_cluster_distribution = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "for path, (original_label, cluster) in path_to_labels.items():\n",
    "    class_to_cluster_distribution[original_label][cluster] += 1\n",
    "\n",
    "# Identify unique original classes and clusters for matrix headers\n",
    "all_original_classes = sorted(class_to_cluster_distribution.keys())\n",
    "all_clusters = sorted(\n",
    "    set(\n",
    "        cluster\n",
    "        for class_distr in class_to_cluster_distribution.values()\n",
    "        for cluster in class_distr.keys()\n",
    "    )\n",
    ")\n",
    "\n",
    "# Print the matrix\n",
    "# Header\n",
    "print(\"\\t\" + \"\\t\".join(f\"C{c}\" for c in all_clusters))\n",
    "print(\"-\" * (8 + 10 * len(all_clusters)))\n",
    "\n",
    "# Rows\n",
    "for original_class in all_original_classes:\n",
    "    counts = [\n",
    "        str(class_to_cluster_distribution[original_class].get(cluster, 0))\n",
    "        for cluster in all_clusters\n",
    "    ]\n",
    "    print(f\"Class {original_class}\\t\" + \"\\t\".join(counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mmpretrain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
