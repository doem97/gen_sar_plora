{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original FID using InceptionV3\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision.models import inception_v3\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import transforms\n",
    "from pytorch_fid import fid_score\n",
    "from scipy.special import kl_div\n",
    "\n",
    "torch.cuda.set_device(2)\n",
    "\n",
    "\n",
    "# Compute FID\n",
    "def compute_fid(model, real_loader, fake_loader):\n",
    "    print(\"Computing FID...\")\n",
    "    real_activations, fake_activations = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for real_images, _ in real_loader:\n",
    "            real_images = real_images.cuda()\n",
    "            real_activations.append(model(real_images))\n",
    "\n",
    "        for fake_images, _ in fake_loader:\n",
    "            fake_images = fake_images.cuda()\n",
    "            fake_activations.append(model(fake_images))\n",
    "\n",
    "    real_activations = torch.cat(real_activations, 0)\n",
    "    fake_activations = torch.cat(fake_activations, 0)\n",
    "\n",
    "    mu1 = torch.mean(real_activations, dim=0)\n",
    "    mu2 = torch.mean(fake_activations, dim=0)\n",
    "\n",
    "    sigma1 = np.cov(real_activations.cpu().numpy(), rowvar=False)\n",
    "    sigma2 = np.cov(fake_activations.cpu().numpy(), rowvar=False)\n",
    "\n",
    "    fid = fid_score.calculate_frechet_distance(\n",
    "        mu1.cpu().numpy(), sigma1, mu2.cpu().numpy(), sigma2\n",
    "    )\n",
    "\n",
    "    return fid\n",
    "\n",
    "\n",
    "# Compute KL Divergence\n",
    "def compute_kl(real_loader, fake_loader):\n",
    "    print(\"Computing KL Divergence...\")\n",
    "    real_histogram = np.zeros(256)\n",
    "    fake_histogram = np.zeros(256)\n",
    "\n",
    "    for real_images, _ in real_loader:\n",
    "        real_histogram += np.histogram(\n",
    "            real_images.numpy().ravel(), bins=256, range=(0, 1)\n",
    "        )[0]\n",
    "\n",
    "    for fake_images, _ in fake_loader:\n",
    "        fake_histogram += np.histogram(\n",
    "            fake_images.numpy().ravel(), bins=256, range=(0, 1)\n",
    "        )[0]\n",
    "\n",
    "    real_histogram /= real_histogram.sum()\n",
    "    fake_histogram /= fake_histogram.sum()\n",
    "\n",
    "    kl = kl_div(real_histogram + 1e-10, fake_histogram + 1e-10).sum()\n",
    "\n",
    "    return kl\n",
    "\n",
    "\n",
    "# Define paths to your folders\n",
    "fake_folder = \"/workspace/dso/playground/fid_kl/data/loragen\"\n",
    "real_folder = \"/workspace/dso/playground/fid_kl/data/fusrs\"\n",
    "pre_trained_ResNet50 = \"/workspace/dso/clsar/outputs/res50_fusrs_v2_pretrain/res50_1x128_lr1e-1+200e+im21k_fusrs_v2/best_f1_score_epoch_158.pth\"\n",
    "\n",
    "# Create data loaders\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((299, 299)),\n",
    "        transforms.Grayscale(num_output_channels=3),\n",
    "        transforms.ToTensor(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "real_dataset = ImageFolder(real_folder, transform=transform)\n",
    "fake_dataset = ImageFolder(fake_folder, transform=transform)\n",
    "\n",
    "# Initialize Inception model\n",
    "inception_model = inception_v3(pretrained=True, transform_input=False).cuda()\n",
    "inception_model.fc = torch.nn.Identity()\n",
    "inception_model = inception_model.eval()\n",
    "\n",
    "# Compute FID and KL Divergence for each category\n",
    "for i, category in enumerate([\"cargo\", \"fishing\", \"dredger\", \"tanker\"]):\n",
    "    print(f\"Category: {category}\")\n",
    "\n",
    "    indices_real = [idx for idx, label in enumerate(real_dataset.targets) if label == i]\n",
    "    indices_fake = [idx for idx, label in enumerate(fake_dataset.targets) if label == i]\n",
    "\n",
    "    real_loader = DataLoader(\n",
    "        torch.utils.data.Subset(real_dataset, indices_real),\n",
    "        batch_size=28,\n",
    "        shuffle=False,\n",
    "    )\n",
    "    fake_loader = DataLoader(\n",
    "        torch.utils.data.Subset(fake_dataset, indices_fake),\n",
    "        batch_size=28,\n",
    "        shuffle=False,\n",
    "    )\n",
    "\n",
    "    fid = compute_fid(inception_model, real_loader, fake_loader)\n",
    "    print(f\"FID: {fid}\")\n",
    "    kl = compute_kl(real_loader, fake_loader)\n",
    "    print(f\"KL Divergence: {kl}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original FID using SAR pre-trained ResNet50\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision.models import inception_v3\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import transforms\n",
    "from pytorch_fid import fid_score\n",
    "from scipy.special import kl_div\n",
    "from mmpretrain import get_model\n",
    "from sklearn.neighbors import KernelDensity\n",
    "from scipy.special import kl_div\n",
    "import numpy as np\n",
    "\n",
    "torch.cuda.set_device(2)\n",
    "\n",
    "\n",
    "# Compute FID\n",
    "def compute_fid(model, real_loader, fake_loader):\n",
    "    print(\"Computing FID...\")\n",
    "    real_activations, fake_activations = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for real_images, _ in real_loader:\n",
    "            real_images = real_images.cuda()\n",
    "            real_activations.append(model(real_images)[0])\n",
    "\n",
    "        for fake_images, _ in fake_loader:\n",
    "            fake_images = fake_images.cuda()\n",
    "            fake_activations.append(model(fake_images)[0])\n",
    "\n",
    "    real_activations = torch.cat(real_activations, 0)\n",
    "    fake_activations = torch.cat(fake_activations, 0)\n",
    "\n",
    "    mu1 = torch.mean(real_activations, dim=0)\n",
    "    mu2 = torch.mean(fake_activations, dim=0)\n",
    "\n",
    "    sigma1 = np.cov(real_activations.cpu().numpy(), rowvar=False)\n",
    "    sigma2 = np.cov(fake_activations.cpu().numpy(), rowvar=False)\n",
    "\n",
    "    fid = fid_score.calculate_frechet_distance(\n",
    "        mu1.cpu().numpy(), sigma1, mu2.cpu().numpy(), sigma2\n",
    "    )\n",
    "\n",
    "    return fid\n",
    "\n",
    "\n",
    "def compute_kl(model, real_loader, fake_loader):\n",
    "    # Extract features from real images\n",
    "    real_features = []\n",
    "    for images, _ in real_loader:\n",
    "        images = images.cuda()\n",
    "        with torch.no_grad():\n",
    "            features = model(images)[0]\n",
    "        real_features.append(features.cpu().numpy())\n",
    "    real_features = np.concatenate(real_features)\n",
    "\n",
    "    # Extract features from fake images\n",
    "    fake_features = []\n",
    "    for images, _ in fake_loader:\n",
    "        images = images.cuda()\n",
    "        with torch.no_grad():\n",
    "            features = model(images)[0]\n",
    "        fake_features.append(features.cpu().numpy())\n",
    "    fake_features = np.concatenate(fake_features)\n",
    "\n",
    "    # Fit KDE to real and fake features\n",
    "    kde_real = KernelDensity(kernel=\"gaussian\", bandwidth=0.2).fit(real_features)\n",
    "    kde_fake = KernelDensity(kernel=\"gaussian\", bandwidth=0.2).fit(fake_features)\n",
    "\n",
    "    # Compute KL divergence\n",
    "    log_dens_real = kde_real.score_samples(real_features)\n",
    "    log_dens_fake = kde_fake.score_samples(fake_features)\n",
    "    kl_real_fake = kl_div(log_dens_real, log_dens_fake).sum()\n",
    "    kl_fake_real = kl_div(log_dens_fake, log_dens_real).sum()\n",
    "\n",
    "    # Return symmetric KL divergence\n",
    "    return 0.5 * (kl_real_fake + kl_fake_real)\n",
    "\n",
    "\n",
    "# Define paths to your folders\n",
    "fake_folder = \"//workspace/dso/gensar/lora/output/sarlora/256/rank/256_fp32_s20000+100e_wp0_bs32_lr1e-03_rank1\"\n",
    "real_folder = \"/workspace/dso/gensar/geneval/data/fusrs\"\n",
    "pre_trained_ResNet50 = \"/workspace/dso/clsar/outputs/res50_fusrs_v2_pretrain/res50_1x128_lr1e-1+200e+im21k_fusrs_v2/best_f1_score_epoch_158.pth\"\n",
    "\n",
    "# Create data loaders\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((299, 299)),\n",
    "        transforms.Grayscale(num_output_channels=3),\n",
    "        transforms.ToTensor(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "real_dataset = ImageFolder(real_folder, transform=transform)\n",
    "fake_dataset = ImageFolder(fake_folder, transform=transform)\n",
    "\n",
    "# Initialize SAR pre-trained ResNet50\n",
    "model = get_model(\n",
    "    \"resnet50_8xb32_in1k\",\n",
    "    head=None,  # to extract only activation vectors\n",
    "    pretrained=pre_trained_ResNet50,\n",
    ").cuda()\n",
    "model = model.eval()\n",
    "\n",
    "# Compute FID and KL Divergence for each category\n",
    "for i, category in enumerate([\"cargo\", \"fishing\", \"dredger\", \"tanker\"]):\n",
    "    print(f\"Category: {category}\")\n",
    "\n",
    "    indices_real = [idx for idx, label in enumerate(real_dataset.targets) if label == i]\n",
    "    indices_fake = [idx for idx, label in enumerate(fake_dataset.targets) if label == i]\n",
    "\n",
    "    real_loader = DataLoader(\n",
    "        torch.utils.data.Subset(real_dataset, indices_real),\n",
    "        batch_size=28,\n",
    "        shuffle=False,\n",
    "    )\n",
    "    fake_loader = DataLoader(\n",
    "        torch.utils.data.Subset(fake_dataset, indices_fake),\n",
    "        batch_size=28,\n",
    "        shuffle=False,\n",
    "    )\n",
    "\n",
    "    fid = compute_fid(model, real_loader, fake_loader)\n",
    "    print(f\"FID: {fid}\")\n",
    "    # kl = compute_kl(model, real_loader, fake_loader)\n",
    "    # print(f\"KL Divergence: {kl}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmpretrain import get_model\n",
    "\n",
    "model = get_model(\n",
    "    \"resnet50_8xb32_in1k\",\n",
    "    # head=dict(num_classes=5),\n",
    "    head=None,\n",
    "    pretrained=\"/workspace/dso/clsar/outputs/res50_fusrs_v2_pretrain/res50_1x128_lr1e-1+200e+im21k_fusrs_v2/best_f1_score_epoch_158.pth\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "model = model.cuda().eval()\n",
    "x = torch.rand((1, 3, 224, 224)).cuda()\n",
    "y = model(x)[0]\n",
    "print(type(y), y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
